{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical \n",
    "\n",
    "def load_images_and_labels(file_path):\n",
    "    dataset = pd.read_csv(os.path.join(file_path, \"_classes.csv\"))\n",
    "    \n",
    "    classes = dataset.columns\n",
    "    file_names = dataset.iloc[:, 0].values\n",
    "    max_label = dataset.iloc[:, 1:].values\n",
    "    max_label = np.argmax(max_label, axis=1)\n",
    "\n",
    "    images = []\n",
    "    new_labels = []\n",
    "\n",
    "    for i, img_path in enumerate(file_names):\n",
    "        full_path = os.path.join(file_path, img_path)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "\n",
    "        img = cv2.imread(full_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        img = img / 255.0\n",
    "\n",
    "        if max_label[i] != 6:\n",
    "            images.append(img)\n",
    "            new_labels.append(max_label[i])\n",
    "\n",
    "    new_labels = to_categorical(new_labels, num_classes=6)\n",
    "\n",
    "    return np.array(images, dtype='float32'), new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 54, 54, 96)        34944     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 54, 54, 96)       384       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 26, 26, 96)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 22, 22, 256)       614656    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 22, 22, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 10, 10, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 8, 8, 384)         885120    \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 6, 6, 384)         1327488   \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 4, 4, 256)         884992    \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 1, 1, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4096)              1052672   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 6)                 24582     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,607,174\n",
      "Trainable params: 21,606,470\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def AlexNet():\n",
    "  inp = layers.Input((224, 224, 3))\n",
    "  x = layers.Conv2D(96, 11, 4, activation='relu')(inp)\n",
    "  x = layers.BatchNormalization()(x)\n",
    "  x = layers.MaxPooling2D(3, 2)(x)\n",
    "  x = layers.Conv2D(256, 5, 1, activation='relu')(x)\n",
    "  x = layers.BatchNormalization()(x)\n",
    "  x = layers.MaxPooling2D(3, 2)(x)\n",
    "  x = layers.Conv2D(384, 3, 1, activation='relu')(x)\n",
    "  x = layers.Conv2D(384, 3, 1, activation='relu')(x)\n",
    "  x = layers.Conv2D(256, 3, 1, activation='relu')(x)\n",
    "  x = layers.MaxPooling2D(3, 2)(x)\n",
    "  x = layers.Flatten()(x)\n",
    "  x = layers.Dense(4096, activation='relu')(x)\n",
    "  x = layers.Dropout(0.5)(x)\n",
    "  x = layers.Dense(4096, activation='relu')(x)\n",
    "  x = layers.Dropout(0.5)(x)\n",
    "  x = layers.Dense(6, activation='softmax')(x) \n",
    "\n",
    "  model = Model(inputs=inp, outputs=x)\n",
    "\n",
    "  return model\n",
    "\n",
    "model = AlexNet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "train_data_dir = 'train/'\n",
    "validation_data_dir = 'valid/'\n",
    "test_data_dir = 'test/'  \n",
    "\n",
    "# Load all images and labels\n",
    "train_images, train_labels = load_images_and_labels(train_data_dir)\n",
    "val_images, val_labels = load_images_and_labels(validation_data_dir)\n",
    "test_images, test_labels = load_images_and_labels(test_data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "192/192 [==============================] - 96s 490ms/step - loss: 1.7631 - accuracy: 0.2275 - val_loss: 2.0595 - val_accuracy: 0.1675\n",
      "Epoch 2/5\n",
      "192/192 [==============================] - 97s 503ms/step - loss: 1.6690 - accuracy: 0.3060 - val_loss: 2.0499 - val_accuracy: 0.2074\n",
      "Epoch 3/5\n",
      "192/192 [==============================] - 98s 512ms/step - loss: 1.5592 - accuracy: 0.3621 - val_loss: 1.6637 - val_accuracy: 0.3182\n",
      "Epoch 4/5\n",
      "192/192 [==============================] - 97s 506ms/step - loss: 1.4629 - accuracy: 0.4099 - val_loss: 2.3108 - val_accuracy: 0.2012\n",
      "Epoch 5/5\n",
      "192/192 [==============================] - 100s 519ms/step - loss: 1.3868 - accuracy: 0.4562 - val_loss: 1.6933 - val_accuracy: 0.3227\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), \n",
    "              loss=\"categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(train_images, train_labels, batch_size=32, epochs=5, validation_data=(val_images, val_labels))\n",
    "\n",
    "model.save('AlexNet_without_unlabeled.h5')\n",
    "\n",
    "#T : Jawaban Benar\n",
    "#Positive / P : Jawaban predict yang nilainya benar\n",
    "# Accuracy: (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "# Precision: (TP) / (TP + FP)\n",
    "\n",
    "# Recall: (TP) / (TP + FN)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "192/192 [==============================] - 97s 504ms/step - loss: 1.2866 - accuracy: 0.4948 - val_loss: 1.4957 - val_accuracy: 0.3935 - lr: 1.0000e-04\n",
      "Epoch 2/5\n",
      "192/192 [==============================] - 99s 515ms/step - loss: 1.1757 - accuracy: 0.5467 - val_loss: 1.5515 - val_accuracy: 0.4227 - lr: 1.0000e-04\n",
      "Epoch 3/5\n",
      "192/192 [==============================] - 98s 511ms/step - loss: 1.0833 - accuracy: 0.5873 - val_loss: 1.6878 - val_accuracy: 0.2962 - lr: 1.0000e-04\n",
      "Epoch 4/5\n",
      "192/192 [==============================] - 98s 513ms/step - loss: 0.9409 - accuracy: 0.6425 - val_loss: 1.5359 - val_accuracy: 0.4452 - lr: 1.0000e-04\n",
      "Epoch 5/5\n",
      "192/192 [==============================] - 99s 514ms/step - loss: 0.8333 - accuracy: 0.6834 - val_loss: 1.5163 - val_accuracy: 0.4474 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# To Continue the Training run this cell\n",
    "\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Use ReduceLR\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=0.00001)\n",
    "\n",
    "# Load the model\n",
    "model = load_model('AlexNet_without_unlabeled.h5')\n",
    "\n",
    "# Continue training\n",
    "model.fit(train_images, train_labels, batch_size=32, epochs=5, validation_data=(val_images, val_labels), callbacks=reduce_lr)\n",
    "\n",
    "model.save('AlexNet_without_unlabeled.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 5s 79ms/step - loss: 1.5163 - accuracy: 0.4474\n",
      "Test Loss: 1.5162811279296875\n",
      "Test Accuracy: 0.4474423825740814\n"
     ]
    }
   ],
   "source": [
    "# Test Accuracy\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('AlexNet_without_unlabeled.h5')\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(val_images, val_labels)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
